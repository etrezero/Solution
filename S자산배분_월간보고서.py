import os
import pandas as pd
import pymysql
from openpyxl import Workbook
from datetime import datetime, timedelta
from dateutil.relativedelta import relativedelta
import calendar
import concurrent.futures
import re

import requests
import yfinance as yf
import concurrent.futures
import pickle



cache_price = r'C:\Covenant\data\Sìì‚°ë°°ë¶„_ì›”ê°„ë³´ê³ ì„œ.pkl'
cache_expiry = timedelta(days=1)


# ë°ì´í„° ê°€ì ¸ì˜¤ê¸° í•¨ìˆ˜ì—ì„œ ì‹œê°„ëŒ€ ì •ë³´ ì œê±°
def fetch_data(code, start, end):
    try:
        session = requests.Session()
        session.verify = False  # SSL ì¸ì¦ì„œ ê²€ì¦ ë¹„í™œì„±í™”
        yf_data = yf.Ticker(code, session=session)
        df_price = yf_data.history(start=start, end=end)['Close'].rename(code)

        # ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ ë³€í™˜ ë° ì¸ë±ìŠ¤ í¬ë§· ì„¤ì •
        df_price = pd.DataFrame(df_price)
        df_price = df_price.ffill().bfill()
        df_price.columns = [code]

        # ì—´ ì´ë¦„ì„ BM_code_dict í‚¤ë¡œ ë¦¬ë„¤ì„
        renamed_columns = {
            col: key 
            for key in dict_BM.items() 
            for col in df_price.columns }
        
        
        df_price = df_price.rename(columns=renamed_columns)

        df_price.index = pd.to_datetime(df_price.index).strftime('%Y-%m-%d')  # ì¸ë±ìŠ¤ë¥¼ %Y-%m-%d í˜•ì‹ìœ¼ë¡œ ë³€í™˜
        df_price.index = pd.to_datetime(df_price.index).tz_localize(None)  # ì‹œê°„ëŒ€ ì •ë³´ ì œê±°

        return df_price
    
    except Exception as e:
        print(f"Error fetch data {code}: {e}")
        return None



# ìºì‹œë¥¼ í†µí•œ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
def Func(code, start, end, batch_size=10):
    
    # ë‚ ì§œ í˜•ì‹ì„ '%Y-%m-%d'ë¡œ ë³€í™˜
    start = pd.to_datetime(start).strftime('%Y-%m-%d')
    end = pd.to_datetime(end).strftime('%Y-%m-%d')
    
    if os.path.exists(cache_price):
        cache_mtime = datetime.fromtimestamp(os.path.getmtime(cache_price))
        if datetime.now() - cache_mtime < cache_expiry:
            with open(cache_price, 'rb') as f:
                print("Loading cache========================")
                return pickle.load(f)

    data_frames = []
    for i in range(0, len(code), batch_size):
        code_batch = code[i:i + batch_size]
        with concurrent.futures.ThreadPoolExecutor() as executor:
            futures = {executor.submit(fetch_data, c, start, end): c for c in code_batch}
            for future in concurrent.futures.as_completed(futures):
                result = future.result()
                if result is not None:
                    data_frames.append(result)

    price_data = pd.concat(data_frames, axis=1) if data_frames else pd.DataFrame()

    with open(cache_price, 'wb') as f:
        pickle.dump(price_data, f)
        print("Data cached================================")

    return price_data




path = rf'C:\Covenant\data\0. ì‚¼ì„±ìƒëª…_ë³€ì•¡_ê´€ë¦¬íŒŒì¼.xlsx'
#ì—‘ì…€ ì €ì¥=======================================================

def save_excel(df, sheetname, index_option=None):

    # path = rf'C:\Covenant\data\Sìì‚°ë°°ë¶„_ì›”ê°„ë³´ê³ ì„œ_202503.xlsx'
    # íŒŒì¼ì´ ì—†ëŠ” ê²½ìš° ìƒˆ Workbook ìƒì„±
    if not os.path.exists(path):
        wb = Workbook()
        wb.save(path)
        print(f"ìƒˆ íŒŒì¼ '{path}' ìƒì„±ë¨.")
    
    # ì¸ë±ìŠ¤ë¥¼ ë‚ ì§œë¡œ ë³€í™˜ ì‹œë„
    try:
        # index_optionì´ Noneì¼ ê²½ìš° ì¸ë±ìŠ¤ë¥¼ í¬í•¨í•˜ê³  ë‚ ì§œ í˜•ì‹ìœ¼ë¡œ ì €ì¥
        if index_option is None or index_option:  # ì¸ë±ìŠ¤ë¥¼ í¬í•¨í•˜ëŠ” ê²½ìš°
            df.index = pd.to_datetime(df.index, errors='coerce')
            df.index = df.index.strftime('%Y-%m-%d')  # ë²¡í„°í™”ëœ ë°©ì‹ìœ¼ë¡œ ë‚ ì§œ í¬ë§· ë³€ê²½
            index = True  # ì¸ë±ìŠ¤ë¥¼ í¬í•¨í•´ì„œ ì €ì¥
        else:
            index = False  # ì¸ë±ìŠ¤ë¥¼ ì œì™¸í•˜ê³  ì €ì¥
    except Exception:
        print("Indexë¥¼ ë‚ ì§œ í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ ì¸ë±ìŠ¤ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
        index = index_option if index_option is not None else True  # ë³€í™˜ ì‹¤íŒ¨ ì‹œì—ë„ ì¸ë±ìŠ¤ë¥¼ í¬í•¨í•˜ë„ë¡ ì„¤ì •

    # DataFrameì„ ì—‘ì…€ ì‹œíŠ¸ë¡œ ì €ì¥
    with pd.ExcelWriter(path, engine='openpyxl', mode='a', if_sheet_exists='replace') as writer:
        df.to_excel(writer, sheet_name=sheetname, index=index)  # index ì—¬ë¶€ ì„¤ì •
        print(f"'{sheetname}' ì €ì¥ ì™„ë£Œ.")



path = rf'C:\Covenant\data\0. ì‚¼ì„±ìƒëª…_ë³€ì•¡_ê´€ë¦¬íŒŒì¼.xlsx'

def read_excel_file(path, sheet_name):

    try:
        if not os.path.exists(path):
            print(f"Error: The file does not exist: {path}")
            return None
        df = pd.read_excel(path, sheet_name=sheet_name, engine='openpyxl')
        print(f"Successfully read the '{sheet_name}' sheet into a DataFrame.")
        return df
    except Exception as e:
        print(f"error occurred : reading the Excel file: {e}")
        return None



# # # ================================================
def execute_query(connection, query):
    try:
        with connection.cursor() as cursor:
            cursor.execute(query)
            result = cursor.fetchall()
            return result
    except Exception as e:
        print(f"Error executing query: {e}")
        return None


def fetch_data(query):
    # MySQL ì—°ê²° ì •ë³´ ì„¤ì •
    connection = pymysql.connect(
        host='192.168.195.55',
        user='solution',
        password='Solution123!',
        database='dt',
        port=3306,
        cursorclass=pymysql.cursors.DictCursor
    )
    try:
        result = execute_query(connection, query)
    finally:
        connection.close()
    
    if result:
        return pd.DataFrame(result)
    else:
        return None


def mainquery(start, end):
    
    cache_Q = rf'C:\Covenant\cache\Sìì‚°ë°°ë¶„_ì¿¼ë¦¬_{start}.pkl'
    cache_Q_expiry = timedelta(days=1)

    
    # ìºì‹œ íŒŒì¼ì´ ì¡´ì¬í•˜ë©´ ë§Œë£Œ ì—¬ë¶€ í™•ì¸
    if os.path.exists(cache_Q):
        cache_mtime = datetime.fromtimestamp(os.path.getmtime(cache_Q))
        if datetime.now() - cache_mtime < cache_Q_expiry:
            # ìºì‹œ ë°ì´í„° ë¡œë“œ
            with open(cache_Q, 'rb') as f:
                cached_data = pickle.load(f)
                print("ğŸ”¹ ìºì‹œì—ì„œ ë°ì´í„° ë¡œë“œ ì™„ë£Œ")
                return cached_data['query1'], cached_data['query2'], cached_data['query3']
    
    
    queries = {
        # í€ë“œë³„ íˆ¬ìë¹„ì¤‘
        'query1': f"""
            SELECT 
                A.STD_DT,               -- ê¸°ì¤€ì¼
                A.FUND_CD,              -- í€ë“œì½”ë“œ
                A.FUND_NM,              -- í€ë“œëª…
                A.ITEM_CD,              -- ì¢…ëª©ì½”ë“œ
                A.ITEM_NM,              -- ì¢…ëª©ëª…
                A.NAST_TAMT_AGNST_WGH,  -- ìˆœìì‚°ë¹„ì¤‘
                A.APLD_UPR,             -- ì ìš©ë‹¨ê°€
                B.TKR_CD                -- í‹°ì»¤ì½”ë“œ (TKR_CD)
            FROM 
                DWPM10530 A
            LEFT JOIN 
                DWPI10021 B
            ON 
                A.ITEM_CD = B.ITEM_CD
            WHERE 
                A.FUND_CD IN (
                    '3JM08', '3JM09', '3JM10', '3JM11', 
                    '3JM12', '3JM13', '4JM03', '4JM04'
                )
                AND A.STD_DT >= '{start}' 
                AND A.STD_DT <= '{end}';
        """,

        # ìˆ˜ì •ê¸°ì¤€ê°€ / ì„¤ì •ì•¡ / ìˆœìì‚°
        'query2': f"""
            SELECT 
                STD_DT,          -- ê¸°ì¤€ì¼
                FUND_CD,         -- í€ë“œì½”ë“œ
                MOD_STPR,        -- ìˆ˜ì •ê¸°ì¤€ê°€
                NAST_AMT        -- ìˆœìì‚°

            FROM
                DWPM10510
            WHERE
                FUND_CD IN (
                    '3JM08', '3JM09', '3JM10', '3JM11', 
                    '3JM12', '3JM13', '4JM03', '4JM04'
                )
                AND STD_DT >= '{Y_ago}' AND STD_DT <= '{end}';
        """,


        # ë¶„ë°°ê¸ˆ
        'query3': f"""
            SELECT 
                PCS_DT, 
                FUND_CD, 
                ACSB_NM,    -- ê³„ì •ê³¼ëª©ëª…
                CR_AMT
                
            FROM 
                DWPM11030
            
            WHERE 
                FUND_CD IN ('3JM08', '3JM09', '3JM10', '3JM11', '3JM12', '3JM13', '4JM03', '4JM04')
                AND PCS_DT >= '{start}' AND PCS_DT <= '{end}';"""
    }

                # OPNG_AMT,        -- ì„¤ì •ê¸ˆì•¡
                # NAST_AMT,        -- ìˆœìì‚°
                # TDD_OPNG_AMT,    -- ë‹¹ì¼ì„¤ì •
                # TDD_CLSR_AMT     -- ë‹¹ì¼í•´ì§€


    results = {}
    with concurrent.futures.ThreadPoolExecutor() as executor:
        future_to_query = {executor.submit(fetch_data, query): name for name, query in queries.items()}
        for future in concurrent.futures.as_completed(future_to_query):
            query_name = future_to_query[future]
            try:
                result = future.result()
                if result is not None:
                    results[query_name] = result
                    print(f"{query_name} Result:\n", result.head())
                else:
                    print(f"{query_name} returned no results.")
            except Exception as e:
                print(f"Error fetching data for {query_name}: {e}")



    # ìºì‹œì— ë°ì´í„° ì €ì¥
    with open(cache_Q, 'wb') as f:
        pickle.dump(results, f)
        print("ğŸ“Œ ë°ì´í„° ìºì‹œ ì €ì¥ ì™„ë£Œ")

    return results.get('query1'), results.get('query2'), results.get('query3')



if __name__ == "__main__":
    # ì˜¤ëŠ˜ ë‚ ì§œ ê¸°ì¤€ìœ¼ë¡œ ì „ì „ì›” ë§ˆì§€ë§‰ ë‚ ê³¼ ì§€ë‚œë‹¬ ë§ˆì§€ë§‰ ë‚  ê³„ì‚°
    today = datetime.today()
    # today = datetime.today() - relativedelta(months=1)

    Y_ago = (datetime.today() - relativedelta(years=1)).strftime('%Y%m%d')


    ì´ë‹¬ì´ˆ = today.replace(day=1)
    ì§€ë‚œë‹¬ë§ = ì´ë‹¬ì´ˆ - timedelta(days=1)
    ì§€ë‚œë‹¬ì´ˆ = ì§€ë‚œë‹¬ë§.replace(day=1) 
    

    #ì›”ê°„ ë³´ê³ ì„œë¥¼ ìœ„í•œ ë‚ ì§œ ì„¤ì •   
    start_1M = ì§€ë‚œë‹¬ì´ˆ.strftime('%Y%m%d')
    end = ì§€ë‚œë‹¬ë§.strftime('%Y%m%d')

    #YTD ë³´ê³ ì„œë¥¼ ìœ„í•œ ì‹œì‘ ë‚ ì§œ ì„¤ì •
    ì—°ì´ˆ = (today.replace(year=today.year, month=1, day=1))
    YTD_start = ì—°ì´ˆ.strftime('%Y%m%d')




    #Startë¥¼ YTDì™€ 1Mì„ ë°”ê¿”ì„œ ì¢…í•© 

    # ********************************************************
    start = start_1M
    # start = YTD_start
    # ********************************************************
    
    sheet = "YTD" if start == YTD_start else "M"

    # main í•¨ìˆ˜ ì‹¤í–‰ :  ê±´ë“¤ì§€ ë§ê²ƒ
    df_weight, df_ê¸°ì¤€ê°€, df_ë¯¸ìˆ˜ë¶„ë°°ê¸ˆ = mainquery(start, end)  



    # # 1M ë°ì´í„° ì²˜ë¦¬
    # # df_weight, df_ê¸°ì¤€ê°€, df_ë¯¸ìˆ˜ë¶„ë°°ê¸ˆ = mainquery('20240101', '20240131')
    # # df_weight, df_ê¸°ì¤€ê°€, df_ë¯¸ìˆ˜ë¶„ë°°ê¸ˆ = mainquery(YTD_start, end)


#? <êµ¬ê°„í‘œì‹œ>===========================================================================

    # Load data
    BM_R = read_excel_file(path, 'BM_Data')


    # data sheet KOSPI200~ìœ ë™ì„±
    BM_R.columns = BM_R.iloc[6]
    BM_R = BM_R.iloc[8:, 1:34]
    BM_R = BM_R.drop(BM_R.columns[1:10], axis=1)
    

    BM_R.reset_index(drop=True, inplace=True)
    BM_R.columns.values[0] = 'Date'
    BM_R.reset_index(drop=True, inplace=True)

    # Set 'Date' as index
    BM_R['Date'] = pd.to_datetime(BM_R['Date'], format='%Y-%m-%d', errors='coerce')
    BM_R.dropna(subset=['Date'], inplace=True)
    BM_R.set_index('Date', inplace=True)

    # Remove duplicate indices
    BM_R = BM_R[~BM_R.index.duplicated(keep='first')]

    print("BM_R=============================", BM_R.head(10))





    # Generate continuous date range
    date_range = pd.date_range(start=BM_R.index.min(), end=BM_R.index.max())
    BM_R = BM_R.reindex(date_range)

    BM_R = BM_R.infer_objects()

    BM_R = BM_R.astype(float)
    BM_R.fillna(0, inplace=True)
    
    BM_R = BM_R.fillna(0)

    # # Print results====================================================

    print("BM_R**************************", BM_R.loc['2025-04-30']*100)



    # BMW =====================================================================
    df_BMW = read_excel_file(path, 'BM_Weight')
    df_BMW = df_BMW.iloc[2:]
    df_BMW.columns = df_BMW.iloc[0]
    df_BMW = df_BMW.drop(index=2)
    df_BMW.reset_index(drop=True, inplace=True)



    # Set 'Date' as index
    df_BMW['Date'] = pd.to_datetime(df_BMW['ìš´ìš©ì¼'], format='%Y-%m-%d', errors='coerce')
    df_BMW.dropna(subset=['ìš´ìš©ì¼'], inplace=True)
    df_BMW.set_index('Date', inplace=True)
    # print("df_BMW:\n", df_BMW)

    # ******ì²˜ìŒì€ ê·¸ëŒ€ë¡œ : ë§ˆì§€ë§‰ì€ +1 *******************
    BMW_50 = df_BMW.iloc[:,1:24].fillna(0).astype(float)
    BMW_30 = df_BMW.iloc[:,24:47].fillna(0).astype(float)
    BMW_70 = df_BMW.iloc[:,47:70].fillna(0).astype(float)
    BMW_í‡´ì§70 = df_BMW.iloc[:,70:93].fillna(0).astype(float)

    BMW_í•´ì™¸ì±„ê¶Œ = df_BMW.iloc[:,93:99].fillna(0).astype(float)
    BMW_êµ­ë‚´ì±„ê¶Œ = df_BMW.iloc[:,99:103].fillna(0).astype(float)

    print("BMW_50.columns====================\n", BMW_50.columns)
    print("BMW_30.columns====================\n", BMW_30.columns)
    print("BMW_70.columns====================\n", BMW_70.columns)
    print("BMW_í‡´ì§70.columns====================\n", BMW_í‡´ì§70.columns)
    print("BMW_í•´ì™¸ì±„ê¶Œ.columns====================\n", BMW_í•´ì™¸ì±„ê¶Œ.columns)
    print("BMW_êµ­ë‚´ì±„ê¶Œ.columns====================\n", BMW_êµ­ë‚´ì±„ê¶Œ.columns)






    # ê° BMW ë°ì´í„°í”„ë ˆì„ì„ startë¶€í„° endê¹Œì§€ í•„í„°ë§========================================
    start_date = pd.to_datetime(start)
    end_date = pd.to_datetime(end)

    BMW_50 = BMW_50.loc[start_date:end_date]
    BMW_30 = BMW_30.loc[start_date:end_date]
    BMW_70 = BMW_70.loc[start_date:end_date]
    BMW_í‡´ì§70 = BMW_í‡´ì§70.loc[start_date:end_date]
    BMW_í•´ì™¸ì±„ê¶Œ = BMW_í•´ì™¸ì±„ê¶Œ.loc[start_date:end_date]
    BMW_êµ­ë‚´ì±„ê¶Œ = BMW_êµ­ë‚´ì±„ê¶Œ.loc[start_date:end_date]


    # í•„í„°ë§ëœ ê²°ê³¼ ì¶œë ¥
    # print("BMW_50 (Filtered)*****************\n", BMW_50)
    # save_excel(BMW_50, "BMW_50", index_option=None)



    # print("BMW_30 (Filtered)====================\n", BMW_30)
    # print("BMW_70 (Filtered)====================\n", BMW_70)
    # print("BMW_í‡´ì§70 (Filtered)====================\n", BMW_í‡´ì§70)
    # print("BMW_í•´ì™¸ì±„ê¶Œ (Filtered)====================\n", BMW_í•´ì™¸ì±„ê¶Œ)
    # print("BMW_êµ­ë‚´ì±„ê¶Œ (Filtered)====================\n", BMW_êµ­ë‚´ì±„ê¶Œ)
    # # # ===========================================================================================

#? <êµ¬ê°„í‘œì‹œ>========================================================================


    # # *  ìì‚°ì°¨ = âˆ‘âˆ‘(APë¹„ì¤‘(i, t-1)-(BMë¹„ì¤‘(i, t-1))*r(i, t))), ìˆ˜ìµì°¨ = âˆ‘âˆ‘((BMë¹„ì¤‘(i, t-1))*(r(k, t) - r(i, t))), ê¸°íƒ€ì°¨ = ì´ˆê³¼ìˆ˜ìµ - ìì‚°ì°¨ - ìˆ˜ìµì°¨ (i = ìì‚°êµ°, t = ì‹œê°„, k = ì¢…ëª©, r = ìˆ˜ìµë¥ )



    # BM_Match =====================================================================
    BM_match = read_excel_file(path, 'BM_Match')
    BM_match = BM_match.iloc[0:,5:9]


    # 1. ì²« ë²ˆì§¸ í–‰ì„ ì»¬ëŸ¼ëª…ìœ¼ë¡œ ì§€ì •
    BM_match.columns = BM_match.iloc[0, :]

    # 2. ì²« ë²ˆì§¸ í–‰ ì œê±°
    BM_match = BM_match.drop(index=0).reset_index(drop=True)

    # 3. Ticker ì»¬ëŸ¼ ë¬¸ìì—´ ì •ë¦¬
    BM_match["Ticker"] = (
        BM_match["Ticker"]
        .str.replace(" US Equity", "", regex=False)
        .str.replace(" KS Equity", "", regex=False)
        .str.strip()
    )

    # 4. ì „ë¶€ NaNì¸ ì—´ ì œê±°
    BM_match.dropna(how='all', axis=0, inplace=True)  # â— ë³€ìˆ˜ í• ë‹¹ ì•ˆ í•¨
    BM_match.rename(columns={"(Name)(BBG)": "Full_name"}, inplace=True)


    print("BM_match.columns******************",  BM_match.columns)

    
    # ì—´ ì´ë¦„ ì •ë¦¬ (ê³µë°± ì œê±°)
    BM_match.columns = BM_match.columns.str.strip()

    # "ì¢…ëª©ì •ë³´" ê¸°ì¤€ìœ¼ë¡œ ì¤‘ë³µ ì œê±° í›„ ì²˜ë¦¬
    BM_match = BM_match.drop_duplicates(subset="ì¢…ëª©ì •ë³´")
    print("BM_match=============================", BM_match)


    dict_BM = BM_match.groupby('ì¢…ëª©ì •ë³´')['Ticker'].apply(list).to_dict()    
    print("dict_BM=============================", dict_BM)

    #? ë”•ì…”ë„ˆë¦¬ í”„ë¦°íŠ¸ í•´ì„œ ë”•íŠ¸ BM ë§Œë“¤ê³  ë³´ì •í•´ì„œ ì¨ë¼!

    # ë³´ì •í•œ ë”•ì…”ë„ˆë¦¬ ë®ìœ¼ì”Œìš°ê³  ì“¸ë•Œ
    dict_BM = {
        'Aerospace&Defense': ['PPA'],
        'Agriculture': ['VEGI'],
        'Consumer Staples': ['XLP'],
        'Financials': ['IYF'],
        'KOSDAQ150': ['229200'],
        'KOSPI200': ['069500'],
        'LBMA Silver': ['SLV'],
        'MSCI AC Asia Ex. Japan': ['AAXJ'],
        'Russell 1000 Growth': ['VUG'],
        'MSCI China': ['MCHI'],
        'MSCI EM': ['IEMG'],
        'MSCI India': ['INDA'],
        'MSCI World': ['ACWI','VTI','VEA'],
        'NASDAQ 100': ['QQQ'],
        'Russell 1000 Value': ['VTV'],
        'S&P500': ['SPY'],
        'S&P500 Energy': ['XLE'],
        'Semiconductor': ['SOXX'],
        'US Dividend': ['SCHD'],
        'US Infrastructure': ['PAVE'],
        'êµ­ë‚´ì±„ê¶Œ': ['273130', '356540', '114460', '365780', '148070', '439870', '190620', '385540'],
        'í•´ì™¸ì±„ê¶Œ': ['BND','IAGG','EMB','LQD','VCIT'],
    }

#     dict_BM = {
        
#         "KOSPI200": {"KSP2NTR Index", ".*069500.*|.*229200.*",},
#         "S&P500": {"SPTR500N Index",".*SPY.*|.*DIA.*|.*MAGS.*",},

#         "MSCI World": {"NDDUWI Index", ".*URTH.*|.*VEA.*|.*VTI.*",},
#         "MSCI AC Asia Ex. Japan": {"NDUECAXJ Index", ".*AAXJ.*|.*VPL.*",},
#         "MSCI China": {"M1CN Index","MCHI",},
#         "MSCI EM": {"NDUEEGF Index", "IEMG",},
#         "MSCI ACWI Growth": {"M1WD000G Index", ".*ACWI.*",},
#         "Russell 1000 Growth": {"RU1GN30U Index",".*IWF.*|.*VUG.*"},
#         "Russell 1000 Value": {"RU10VATR Index",".*.*VTV.*"},

#         "NASDAQ 100": {"XNDX Index", ".*QQQ.*|.*QQQM.*",},
#         "Semiconductor": {"XSOX Index", "SOXX",},
#         "US Dividend": {"TGPVAN Index", "SCHD",},
#         "Consumer Staples": {"SP5NCONS Index", ".*XLP.*|.*IYK.*|.*XLY.*",},
#         "US Infrastructure": {"NYFSINFT Index", "PAVE",},
#         "S&P500 Energy": {"SPTRENRS Index", "XLE",},
#         "LBMA Silver": {"SLVRLND Index", "SLV",},

#         "Financials": {"SP5NFINL Index", "IYF",},
#         "Aerospace&Defense": {"S5AEROTR Index", "PPA",},
#         "MSCI India": {"NDEUSIA Index", "INDA",},



#         "êµ­ë‚´ì±„ê¶Œ": {".*356540.*|.*114460.*|.*365780.*|.*148070.*|.*439870.*|.*273130.*|.*385540.*|.*190620.*"},
#         "í•´ì™¸ì±„ê¶Œ": {".*BND.*|.*BNDX|.*LQD.*|.*VCLT.*|.*VCIT.*|.*EMB.*|.*IAGG.*"},




#         # "KAPì¢…í•©": {"KBPMABIN Index", "356540.KS",},
#         # "KAPêµ­ê³ ì±„10ë…„": {"KAP KTB 10y TR Index", "356540.KS",},
#         # "KAPêµ­ê³ ì±„30ë…„": {"KBPM30TR Index", "356540.KS",},
#         # "MMF": {"MMF", "356540.KS",},
#         # "ê¸°ì¤€ê¸ˆë¦¬": {"KOCRD Index", "356540.KS",},


#         # "Barclays Global Aggregate TR Hedged": {"LEGATRUH Index", "BND"},
#         # "DM Sovereign": {"LT02TRUU Index", "BND"},
#         # "EM Sovereign (USD)": {"BURCTRUU Index", "EMB"},
#         # "US short-term IG": {"BUC1TRUU Index", "VCIT"},
#         # "US Long-term IG": {"BCR5TRUU Index", "VCLT"},
#         # "US High Yield": {"LF98TRUU Index", "HYG"},

    


#         # "êµ­ë‚´ì±„ê¶Œ": ".*ì±„ê¶Œ.*|.*êµ­ê³ .*|.*êµ­ì±„.*|.*í†µì•ˆ.*|.*ì¤‘ê¸°.*",
#         # "í•´ì™¸ì±„ê¶Œ": ".*BND.*|.*LQD.*|.*VCLT.*|.*VCIT.*|.*EMB.*",
        
#         # "ACE ì¢…í•©":".*356540.*",
#         # "ACE êµ­ê³ ì±„3ë…„": ".*114460.*",
#         # "ACE êµ­ê³ ì±„10ë…„": ".*365780.*",
#         # 'KOSEF êµ­ê³ ì±„10ë…„': '.*148070.*',
#         # "KODEX êµ­ê³ ì±„30ë…„" : ".*439870.*",

#         # "KODEX ì¢…í•©": ".*273130.*",
#         # "RISE ì¢…í•©": ".*385540.*",
#         # "KBSTAR ì¢…í•©": ".*385540.*",

#     }




    #? ì—´ ì´ë¦„ì„ dict_BMì— ìˆëŠ” ê°’ìœ¼ë¡œ ë§¤í•‘========================
    
    # ì˜µì…˜ ì…ë ¥ ì•ˆí•˜ë©´ ê·¸ë£¹í•©ê³„ False
    def rename_col_to_dict_value(df, dict, groupby_sum: bool = False):
        
        rename_map = {
            col: next(
                (key for key, value in dict.items()
                    if isinstance(value, list) and any(item in col for item in value)
                    or (isinstance(value, str) and value in col)), col
            ) for col in df.columns
        }
        df = df.rename(columns=rename_map)

        if groupby_sum:
            df = df.groupby(df.columns, axis=1).sum()

        return df

    #? dfì˜ ì—´ ì´ë¦„ì„ dict_BMì— ìˆëŠ” ê°’ìœ¼ë¡œ ë§¤í•‘========================
    












#  #? ======================================================================================



    df_ë¯¸ìˆ˜ë¶„ë°°ê¸ˆ = df_ë¯¸ìˆ˜ë¶„ë°°ê¸ˆ.loc[
        (df_ë¯¸ìˆ˜ë¶„ë°°ê¸ˆ['ACSB_NM'] == 'ETFë¶„ë°°ê¸ˆìˆ˜ìµ') | 
        (df_ë¯¸ìˆ˜ë¶„ë°°ê¸ˆ['ACSB_NM'] == 'ì§‘í•©íˆ¬ìì¦ê¶Œë¶„ë°°ê¸ˆìˆ˜ìµ') |
        (df_ë¯¸ìˆ˜ë¶„ë°°ê¸ˆ['ACSB_NM'] == 'ì£¼ì‹ë°°ë‹¹ê¸ˆìˆ˜ìµ') 
    ]


    PV_ë¯¸ìˆ˜ë¶„ë°°ê¸ˆ = df_ë¯¸ìˆ˜ë¶„ë°°ê¸ˆ.pivot_table(
                index='PCS_DT',
                columns=['FUND_CD', 'ACSB_NM'],
                values='CR_AMT',
                aggfunc='sum',
    )

    # print("PV_ë¯¸ìˆ˜ë¶„ë°°ê¸ˆ==============", PV_ë¯¸ìˆ˜ë¶„ë°°ê¸ˆ)


    PV_ë¯¸ìˆ˜ë¶„ë°°ê¸ˆ = PV_ë¯¸ìˆ˜ë¶„ë°°ê¸ˆ.groupby(level=0, axis=1).sum()
    # print("PV_ë¯¸ìˆ˜ë¶„ë°°ê¸ˆ==============", PV_ë¯¸ìˆ˜ë¶„ë°°ê¸ˆ)



    PV_ìˆœìì‚° = df_ê¸°ì¤€ê°€.pivot_table(
                index='STD_DT',
                columns=['FUND_CD'],
                values='NAST_AMT',
                aggfunc='sum',
    )

    # print("PV_ìˆœìì‚°==============", PV_ìˆœìì‚°)
    


    # ë‘ ë°ì´í„°í”„ë ˆì„ì˜ ì¸ë±ìŠ¤ ì´ë¦„ í†µì¼
    PV_ë¯¸ìˆ˜ë¶„ë°°ê¸ˆ.index.name = 'STD_DT'
    PV_ìˆœìì‚°.index.name = 'STD_DT'

    # ë™ì¼í•œ FUND_CDë¥¼ ê¸°ì¤€ìœ¼ë¡œ ë‚˜ëˆ„ê¸°
    PV_ë¶„ë°°ê¸ˆë¹„ìœ¨ = PV_ë¯¸ìˆ˜ë¶„ë°°ê¸ˆ.div(PV_ìˆœìì‚°, level=0, axis=1).fillna(0)

    # print("PV_ë¶„ë°°ê¸ˆë¹„ìœ¨==============", PV_ë¶„ë°°ê¸ˆë¹„ìœ¨)



    # ë”•ì…”ë„ˆë¦¬ ìƒì„±
    dict_FUND_CD = {
        # '3JM08': '30',
        # '3JM09': '30',
        # '3JM10': '30',
        # '3JM11': '50',
        # '3JM12': '30',
        '3JM13': '50',
        # '4JM03': '70',
        # '4JM04': 'í‡´ì§70'
    }

    # FUND_CD ëª©ë¡
    List_FUND_CD = list(dict_FUND_CD.keys())


    # ì œì™¸í•  ë¬¸ìì—´ ë¦¬ìŠ¤íŠ¸
    exclude = ['KRW/USD', 'FX', 'ë¯¸ìˆ˜ê¸ˆ', 'ê¸°íƒ€ìì‚°', 'DEPOSIT', 'ì˜ˆê¸ˆ', 'REPO', 'ì›ì²œì„¸', 'ë¶„ë°°ê¸ˆ', 'ë¯¸ì§€ê¸‰ê¸ˆ', 'CALL']
    
    

    # ì œì™¸ ì¡°ê±´ì— ë§ëŠ” ë°ì´í„° í•„í„°ë§
    df_weight = df_weight[~df_weight['ITEM_NM'].str.contains('|'.join(exclude), na=False)]

    df_weight = df_weight[~df_weight['ITEM_CD'].str.contains('FXW', na=False)]

    print("df_weight=======================", df_weight)


    # TKR_CD í‚¤ë¡œ, ITEM_NMì„ ê°’ìœ¼ë¡œ í•˜ëŠ” ë”•ì…”ë„ˆë¦¬ ìƒì„±
    dict_ITEM = (
        df_weight[['ITEM_NM', 'TKR_CD', 'ITEM_CD']]
        .dropna(subset=['ITEM_NM'])  # ITEM_NMì´ NaNì¸ í–‰ ì œê±°
        .drop_duplicates(subset=['ITEM_NM'])  # ITEM_NM ì¤‘ë³µ ì œê±°
        .set_index('ITEM_NM')
        .to_dict(orient='index')
    )
    

    # TKR_CDì—ì„œ " US" ì œê±°
    dict_ITEM = {
        key: {
            **value, 
            'TKR_CD': value['TKR_CD'].replace(" US", "") if 'TKR_CD' in value and value['TKR_CD'] else value['TKR_CD']
        } for key, value in dict_ITEM.items()
    }

    # print("dict_ITEM=======================", dict_ITEM)

#  #? ======================================================================================







    def generate_PV_ê¸°ì¤€ê°€(List_FUND_CD, df_ê¸°ì¤€ê°€):
        PV_ê¸°ì¤€ê°€ = {}
        í€ë“œ_R = {}
        í€ë“œ_cum = {}


        for code in List_FUND_CD:
            # ë°ì´í„° í•„í„°ë§
            df_filtered = df_ê¸°ì¤€ê°€.loc[df_ê¸°ì¤€ê°€['FUND_CD'] == code]

            # ê¸°ì¤€ê°€ í”¼ë²— í…Œì´ë¸” ìƒì„±
            PV = df_filtered.pivot_table(
                index='STD_DT',
                values='MOD_STPR',
                aggfunc='mean',
            )

            # ê²°ì¸¡ê°’ ì²˜ë¦¬
            PV = PV.fillna(0).ffill().bfill()

            # ìˆ˜ìµë¥  ë° ëˆ„ì  ìˆ˜ìµë¥  ê³„ì‚°
            R = PV.pct_change().fillna(0)
            cum = (1 + R).cumprod() - 1

            # ì‚¬ì „ì— ì €ì¥
            PV_ê¸°ì¤€ê°€[code] = PV
            í€ë“œ_R[code] = R
            í€ë“œ_cum[code] = cum

            # print(f"PV_ê¸°ì¤€ê°€ {code}====================================\n", PV.head())
            # print(f"í€ë“œ_R {code}====================================\n", R.head())
            # print(f"í€ë“œ_cum {code}====================================\n", cum.head())


        # ? ê¸°ì—¬ë„J ì—…ë°ì´íŠ¸ì— í•„ìš” : Group_ê¸°ì¤€ê°€
        Group_ê¸°ì¤€ê°€ = pd.concat(PV_ê¸°ì¤€ê°€.values(), axis=1)
        Group_ê¸°ì¤€ê°€.columns = List_FUND_CD  # ì»¬ëŸ¼ëª…: í€ë“œì½”ë“œ


        # with pd.ExcelWriter(path, engine='openpyxl', mode='a', if_sheet_exists='replace') as writer:
        #     for code in PV_ê¸°ì¤€ê°€.keys():
        #         PV_ê¸°ì¤€ê°€[code].to_excel(writer, sheet_name=f"PV_ê¸°ì¤€ê°€_{code}_{sheet}")
        #         í€ë“œ_R[code].to_excel(writer, sheet_name=f"R_{code}_{sheet}")
        #         í€ë“œ_cum[code].to_excel(writer, sheet_name=f"cum_{code}_{sheet}")
        #         print(f"'{code}' ê´€ë ¨ ë°ì´í„° ì €ì¥ ì™„ë£Œ.")

        return PV_ê¸°ì¤€ê°€, í€ë“œ_R, í€ë“œ_cum, Group_ê¸°ì¤€ê°€


    PV_ê¸°ì¤€ê°€, í€ë“œ_R, í€ë“œ_cum, Group_ê¸°ì¤€ê°€ = generate_PV_ê¸°ì¤€ê°€(List_FUND_CD, df_ê¸°ì¤€ê°€)
    
    print(f"Group_ê¸°ì¤€ê°€====================================\n", PV_ê¸°ì¤€ê°€)
    save_excel(Group_ê¸°ì¤€ê°€, "Group_ê¸°ì¤€ê°€", index_option=None)



    def generate_PV_ë‹¨ê°€(List_FUND_CD, df_weight, dict_ITEM):
        PV_ë‹¨ê°€ = {}
        for code in List_FUND_CD:
            df_filtered = df_weight.loc[df_weight['FUND_CD'] == code]

            PV = df_filtered.pivot_table(
                index='STD_DT',
                columns='ITEM_NM',
                values='APLD_UPR',  #ì ìš©ë‹¨ê°€
                aggfunc='mean',
            )

            
            PV = PV.replace(0, pd.NA).ffill().bfill()

            PV.rename(columns=lambda col: next(
                (value['TKR_CD'] if value['TKR_CD'] else value['ITEM_CD'][-9:-3])
                for key, value in dict_ITEM.items() if col == key
            ), inplace=True)

            PV_ë‹¨ê°€[code] = PV
            # print(f"PV_ë‹¨ê°€ {code} ====================================\n", PV.head())

        # with pd.ExcelWriter(path, engine='openpyxl', mode='a', if_sheet_exists='replace') as writer:
        #     for code, PV in PV_ë‹¨ê°€.items():
        #         PV.to_excel(writer, sheet_name=f"PV_ë‹¨ê°€_{code}_{sheet}", index=True)
        #         print(f"'PV_ë‹¨ê°€_{code}_{sheet}' ì—‘ì…€ ì €ì¥ ì™„ë£Œ.")

        return PV_ë‹¨ê°€

    PV_ë‹¨ê°€ = generate_PV_ë‹¨ê°€(List_FUND_CD, df_weight, dict_ITEM)




    def generate_PV_W(List_FUND_CD, df_weight, dict_ITEM):
        PV_W = {}

        for code in List_FUND_CD:
            df_filtered = df_weight.loc[df_weight['FUND_CD'] == code]

            PV = df_filtered.pivot_table(
                index='STD_DT',
                columns='ITEM_NM',
                values='NAST_TAMT_AGNST_WGH',
                aggfunc='mean',
            )

            PV = PV.fillna(0) / 100

            PV.rename(columns=lambda col: next(
                (value['TKR_CD'] if value['TKR_CD'] else value['ITEM_CD'][-9:-3])
                for key, value in dict_ITEM.items() if col == key
            ), inplace=True)
            
            PV.columns = PV.columns.astype(str)
            PV_W[code] = PV
            
            print(f"PV_W_{code}_{sheet}====================================\n", PV.head())

        # with pd.ExcelWriter(path, engine='openpyxl', mode='a', if_sheet_exists='replace') as writer:
        #     for code, pv_table in PV_W.items():
        #         pv_table.to_excel(writer, sheet_name=f"PV_W_{code}_{sheet}", index=True)
        #         print(f"'PV_W_{code}_{sheet}' ì €ì¥ ì™„ë£Œ.")

        return PV_W

    PV_W = generate_PV_W(List_FUND_CD, df_weight, dict_ITEM)



    def generate_ctr(PV_W, PV_ë‹¨ê°€, List_FUND_CD):
        ctr = {}
        ë‹¨ê°€_R = {}

        for code in List_FUND_CD:
            common_columns = PV_W[code].columns.astype(str).intersection(PV_ë‹¨ê°€[code].columns.astype(str))

            if not common_columns.empty:
                ë‹¨ê°€_R = PV_ë‹¨ê°€[code].pct_change().fillna(0)
                ë‹¨ê°€_R.replace([float('inf'), float('-inf')], 0, inplace=True)

                ë‹¨ê°€_R_filtered = ë‹¨ê°€_R[common_columns]
                PV_W_filtered = PV_W[code][common_columns]

                try:
                    ctr_code = PV_W_filtered * ë‹¨ê°€_R_filtered
                    ctr_code

                    ctr[code] = ctr_code

                    # print(f"ctr_{code}_{sheet} ====================================\n", ctr_code.head())
                except ValueError as e:
                    print(f"ctr_{code}_{sheet} ìƒì„± ì¤‘ ì—ëŸ¬ ë°œìƒ: {e}")
            else:
                print(f"ê³µí†µ ì—´ì´ ì—†ì–´ ctr_{code}_{sheet} ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

        
        # with pd.ExcelWriter(path, engine='openpyxl', mode='a', if_sheet_exists='replace') as writer:
        #     for code, ctr_table in ctr.items():
        #         ë‹¨ê°€_R.to_excel(writer, sheet_name=f"ë‹¨ê°€_R{code}", index=True)
        #         print(f"'ë‹¨ê°€_R{code}' ì €ì¥ ì™„ë£Œ.")

        #     for code, ctr_table in ctr.items():
        #         ctr_table.to_excel(writer, sheet_name=f"ctr_{code}_{sheet}", index=True)
        #         print(f"'ctr_{code}_{sheet}' ê°œë³„ì¢…ëª© ì €ì¥ ì™„ë£Œ.")


        return ctr, ë‹¨ê°€_R

    PV_ctr, ë‹¨ê°€_R = generate_ctr(PV_W, PV_ë‹¨ê°€, List_FUND_CD)
    
    








# ?====================================================================================


    def generate_AP_W(PV_W, dict_BM):
        AP_W = {}

        for code, pv_w_df in PV_W.items():
            # ê° í€ë“œë³„ DataFrameì— ëŒ€í•´ ì—´ ì´ë¦„ ë¦¬ë„¤ì„ ë° groupby sum
            ap_w_df = rename_col_to_dict_value(pv_w_df, dict_BM, groupby_sum=True)

            # AP_Wì— ì €ì¥
            AP_W[code] = ap_w_df

            # ì—‘ì…€ ì €ì¥
            # save_excel(ap_w_df, f"AP_W_{code}", index_option=None)
            print(f"AP_W_{code} ====================================\n", ap_w_df.head())

        return AP_W

    # AP_W ìƒì„± í˜¸ì¶œ
    AP_W = generate_AP_W(PV_W, dict_BM)







    def generate_EX_W(AP_W, dict_FUND_CD, BMW_30, BMW_50, BMW_70, BMW_í‡´ì§70):
        EX_W = {}

        for code, ap_w_df in AP_W.items():
            # dict_FUND_CDì—ì„œ í•´ë‹¹ í€ë“œ ì½”ë“œì— í•´ë‹¹í•˜ëŠ” ê°’ì„ ê°€ì ¸ì˜´
            fund_name = dict_FUND_CD.get(code, "")
            print(f"fund_name============ {fund_name}")

            # BMW ì„ íƒ ì¡°ê±´
            if "30" in fund_name:
                bmw_df = BMW_30.copy()
            elif "50" in fund_name:
                bmw_df = BMW_50.copy()
            elif "70" in fund_name and "í‡´ì§" not in fund_name:
                bmw_df = BMW_70.copy()
            elif "í‡´ì§70" in fund_name:
                bmw_df = BMW_í‡´ì§70.copy()
            else:
                print(f"{code}ì— ëŒ€í•œ BMW ë§¤ì¹­ ì¡°ê±´ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                continue

            # ì¸ë±ìŠ¤ë¥¼ datetime í˜•ì‹ìœ¼ë¡œ ë³€í™˜ (í•„ìš” ì‹œ)
            ap_w_df.index = pd.to_datetime(ap_w_df.index, errors="coerce")
            bmw_df.index = pd.to_datetime(bmw_df.index, errors="coerce")

            # ì¸ë±ìŠ¤ ë§ì¶¤
            ap_w_df = ap_w_df.reindex(bmw_df.index).fillna(0)
            bmw_df = bmw_df.reindex(ap_w_df.index).fillna(0)

            # ê³µí†µ ì—´ í™•ì¸
            common_columns = list(set(ap_w_df.columns) & set(bmw_df.columns))

            if not common_columns:
                print(f"ê³µí†µ ì—´ì´ ì—†ìŠµë‹ˆë‹¤: {code}")
                continue

            # AP_Wì™€ BMW ì°¨ì´ ê³„ì‚°
            ex_w_df = ap_w_df[common_columns] - bmw_df[common_columns]

            # ê²°ê³¼ ì €ì¥
            EX_W[code] = ex_w_df
            # print(f"EX_W_{code} ====================================\n", ex_w_df.head())
        
        # # ì—‘ì…€ ì €ì¥
        # with pd.ExcelWriter(path, engine="openpyxl", mode="a", if_sheet_exists="replace") as writer:
        #     for code, ex_w_df in EX_W.items():
        #         ex_w_df.to_excel(writer, sheet_name=f"EX_W_{code}_{sheet}", index=True)
        #         print(f"'EX_W_{code}_{sheet}' ì €ì¥ ì™„ë£Œ.")

        return EX_W

    # EX_W ìƒì„±
    EX_W = generate_EX_W(AP_W, dict_FUND_CD, BMW_30, BMW_50, BMW_70, BMW_í‡´ì§70)











    def generate_ìì‚°ì°¨(PV_ctr, EX_W, dict_FUND_CD, BMW_30, BMW_50, BMW_70, BMW_í‡´ì§70, BM_R, dict_BM):
        ìì‚°ì°¨ = {}

        for code, ex_w_df in EX_W.items():
            print(f"Processing ìì‚°ì°¨ for {code}")

            # dict_FUND_CDì—ì„œ í•´ë‹¹ í€ë“œ ì½”ë“œì— ë§ëŠ” BMW ì„ íƒ
            fund_name = dict_FUND_CD.get(code, "")
            if "30" in fund_name:
                bm_w_df = BMW_30.copy()
            elif "50" in fund_name:
                bm_w_df = BMW_50.copy()
            elif "70" in fund_name and "í‡´ì§" not in fund_name:
                bm_w_df = BMW_70.copy()
            elif "í‡´ì§70" in fund_name:
                bm_w_df = BMW_í‡´ì§70.copy()
            else:
                print(f"{code}ì— ëŒ€í•œ BMW ë§¤ì¹­ ì¡°ê±´ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                continue

            # PV_ctrì—ì„œ ì¸ë±ìŠ¤ ì°¸ì¡°
            if code in PV_ctr:
                target_index = PV_ctr[code].index
            else:
                print(f"{code}ì— ëŒ€í•œ PV_ctr ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                continue

            # ì¸ë±ìŠ¤ ë° ì—´ ì´ë¦„ ì •ë ¬
            bm_w_df = bm_w_df.reindex(target_index).fillna(0)
            bm_r_df = BM_R.reindex(target_index).fillna(0)
            ex_w_df = ex_w_df.reindex(target_index).fillna(0)
            

            ex_w_df = rename_col_to_dict_value(ex_w_df, dict_BM)
            bm_w_df = rename_col_to_dict_value(bm_w_df, dict_BM)
            bm_r_df = rename_col_to_dict_value(bm_w_df, dict_BM)

            # ê³µí†µ ì—´ í™•ì¸
            common_columns = list(
                set(ex_w_df.columns) & set(bm_w_df.columns) & set(bm_r_df.columns)
            )
            if not common_columns:
                print(f"ê³µí†µ ì—´ì´ ì—†ìŠµë‹ˆë‹¤: {code}")
                continue

            # ê³µí†µ ì—´ë¡œ ë°ì´í„° í•„í„°ë§
            ex_w_filtered = ex_w_df[common_columns]
            bm_r_filtered = bm_r_df[common_columns]

            # ìì‚° ë°°ë¶„ íš¨ê³¼ ê³„ì‚°
            try:
                ìì‚°ì°¨_df = ex_w_filtered * bm_r_filtered

                # ì²« ë²ˆì§¸ ê°’ì„ 0ìœ¼ë¡œ ë¦¬ì…‹í•˜ê³  ëˆ„ì  ìˆ˜ìµë¥  ê³„ì‚°
                ìì‚°ì°¨_df.iloc[0] = 0
                ìì‚°ì°¨_df = ìì‚°ì°¨_df.cumsum()

                # ê²°ê³¼ ì €ì¥
                ìì‚°ì°¨[code] = ìì‚°ì°¨_df.fillna(0)
                # print(f"ìì‚°ì°¨ for {code} ====================================\n", ìì‚°ì°¨_df.head())

                # !ì—‘ì…€ ì €ì¥  == ì£¼ì„ í’€ì§€ ë§ê²ƒ ì•„ë˜ì™€ ê²¹ì¹¨
                # with pd.ExcelWriter(path, engine="openpyxl", mode="a", if_sheet_exists="replace") as writer:
                #     ìì‚°ì°¨_df.to_excel(writer, sheet_name=f"ìì‚°ì°¨_{code}_{sheet}", index=True)
                #     print(f"ìì‚°ì°¨_{code}_{sheet} ì €ì¥ ì™„ë£Œ.")

            except Exception as e:
                print(f"Error calculating ìì‚°ì°¨ for {code}: {e}")

        return ìì‚°ì°¨

    # Example call
    ìì‚°ì°¨ = generate_ìì‚°ì°¨(PV_ctr, EX_W, dict_FUND_CD, BMW_30, BMW_50, BMW_70, BMW_í‡´ì§70, BM_R, dict_BM)



    def generate_ìˆ˜ìµì°¨(PV_ctr, AP_W, dict_FUND_CD, BMW_30, BMW_50, BMW_70, BMW_í‡´ì§70, BM_R, ë‹¨ê°€_R, dict_BM):
        ìˆ˜ìµì°¨ = {}

        for code, ctr_df in PV_ctr.items():
            print(f"Processing ìˆ˜ìµì°¨ for {code}")

            # dict_FUND_CDì—ì„œ í•´ë‹¹ í€ë“œ ì½”ë“œì— ë§ëŠ” BMW ì„ íƒ
            fund_name = dict_FUND_CD.get(code, "")
            if "30" in fund_name:
                bm_w_df = BMW_30.copy()
            elif "50" in fund_name:
                bm_w_df = BMW_50.copy()
            elif "70" in fund_name and "í‡´ì§" not in fund_name:
                bm_w_df = BMW_70.copy()
            elif "í‡´ì§70" in fund_name:
                bm_w_df = BMW_í‡´ì§70.copy()
            else:
                print(f"{code}ì— ëŒ€í•œ BMW ë§¤ì¹­ ì¡°ê±´ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                continue

            # AP_W ê°€ì ¸ì˜¤ê¸°
            if code not in AP_W:
                print(f"{code}ì— ëŒ€í•œ AP_Wê°€ ì—†ìŠµë‹ˆë‹¤.")
                continue

            ap_w_df = AP_W[code]

            # ì¸ë±ìŠ¤ ë° ì—´ ì´ë¦„ ì •ë ¬
            ap_w_df = ap_w_df.reindex(ctr_df.index).fillna(0)
            bm_w_df = bm_w_df.reindex(ctr_df.index).fillna(0)
            bm_r_df = BM_R.reindex(ctr_df.index).fillna(0)
            ë‹¨ê°€_r_df = ë‹¨ê°€_R.reindex(ctr_df.index).fillna(0)


            ap_w_df = rename_col_to_dict_value(ap_w_df, dict_BM)
            bm_w_df = rename_col_to_dict_value(bm_w_df, dict_BM)
            bm_r_df = rename_col_to_dict_value(bm_r_df, dict_BM)
            ë‹¨ê°€_r_df = rename_col_to_dict_value(ë‹¨ê°€_r_df, dict_BM)
            ctr_df = rename_col_to_dict_value(ctr_df, dict_BM)

            # print("ctr_df###################", ctr_df)

            # ê³µí†µ ì—´ í™•ì¸
            common_columns = list(
                set(ctr_df.columns.astype(str)) & set(ap_w_df.columns.astype(str)) & set(bm_w_df.columns.astype(str)) & set(bm_r_df.columns.astype(str)) & set(ë‹¨ê°€_r_df.columns.astype(str))
            )
            if not common_columns:
                print(f"ê³µí†µ ì—´ì´ ì—†ìŠµë‹ˆë‹¤: {code}")
                continue

            # ê³µí†µ ì—´ë¡œ ë°ì´í„° í•„í„°ë§
            ap_w_filtered = ap_w_df[common_columns]
            bm_w_filtered = bm_w_df[common_columns]
            bm_r_filtered = bm_r_df[common_columns]
            bm_ctr_filtered = bm_w_filtered * bm_r_filtered
            ë‹¨ê°€_r_filtered = ë‹¨ê°€_r_df[common_columns]
            ctr_df_filtered = ctr_df[common_columns]

            # ë™ì¼í•œ ì—´ ì´ë¦„ìœ¼ë¡œ ê·¸ë£¹í™”í•˜ì—¬ í•©ê³„ ê³„ì‚°
            ctr_df_grouped = ctr_df_filtered.groupby(ctr_df_filtered.columns, axis=1).sum()
            ap_w_filtered_grouped = ap_w_filtered.groupby(ap_w_filtered.columns, axis=1).sum()
            bm_w_filtered_grouped = bm_w_filtered.groupby(bm_w_filtered.columns, axis=1).sum()
            bm_r_filtered_grouped = bm_r_filtered.groupby(bm_r_filtered.columns, axis=1).sum()
            ë‹¨ê°€_r_filtered_grouped = ë‹¨ê°€_r_filtered.groupby(ë‹¨ê°€_r_filtered.columns, axis=1).sum()


            # í™•ì¸ ì¶œë ¥
            print("**************bm_w_filtered_grouped**************", bm_w_filtered_grouped)
            print("**************ctr_df_grouped**************", ctr_df_grouped)

            # ë™ì¼í•œ ì—´ ì´ë¦„ë¼ë¦¬ ë‚˜ëˆ„ê¸° ìœ„í•´ êµì§‘í•©ì„ ì°¾ê³  ë‚˜ëˆ„ê¸°
            common_columns_for_div = list(set(ctr_df_grouped.columns) & set(ap_w_filtered_grouped.columns))

            # ê°€ì¤‘í‰ê· ìˆ˜ìµë¥  ê³„ì‚° (ë™ì¼í•œ ì—´ ì´ë¦„ë¼ë¦¬ ë‚˜ëˆ„ê¸°)
            ê°€ì¤‘í‰ê· ìˆ˜ìµë¥  = ctr_df_grouped[common_columns_for_div].div(ap_w_filtered_grouped[common_columns_for_div])
            ê°€ì¤‘í‰ê· ìˆ˜ìµë¥  = ê°€ì¤‘í‰ê· ìˆ˜ìµë¥ .fillna(0)

            # ì¢…ëª© ì„ íƒ íš¨ê³¼ ê³„ì‚°
            try:
                ìˆ˜ìµì°¨_df = bm_w_filtered_grouped * (ê°€ì¤‘í‰ê· ìˆ˜ìµë¥  - bm_r_filtered_grouped)
                ìˆ˜ìµì°¨_df.iloc[0] = 0
                ìˆ˜ìµì°¨_df = ìˆ˜ìµì°¨_df.cumsum()
                ìˆ˜ìµì°¨[code] = ìˆ˜ìµì°¨_df.fillna(0)
                # print(f"ìˆ˜ìµì°¨ for {code} ====================================\n", ìˆ˜ìµì°¨_df.head())

                ìì‚°ì°¨_df = bm_r_filtered_grouped * (ap_w_filtered_grouped - bm_w_filtered_grouped)
                ìì‚°ì°¨_df.iloc[0] = 0
                ìì‚°ì°¨_df = ìì‚°ì°¨_df.cumsum()
                ìì‚°ì°¨[code] = ìì‚°ì°¨_df.fillna(0)
                # print(f"ìì‚°ì°¨ for {code} ====================================\n", ìì‚°ì°¨_df.head())


                # # ì—‘ì…€ ì €ì¥ (ì „ì²´ ë¹„í™œì„±í™” í• ê²ƒ - í…ŒìŠ¤íŠ¸ìš©ì„)
                # with pd.ExcelWriter(path, engine="openpyxl", mode="a", if_sheet_exists="replace") as writer:
                #     ìˆ˜ìµì°¨_df.to_excel(writer, sheet_name=f"ìˆ˜ìµì°¨_{code}_{sheet}", index=True)
                #     ìì‚°ì°¨_df.to_excel(writer, sheet_name=f"ìì‚°ì°¨_{code}_{sheet}", index=True)
                #     bm_w_filtered_grouped.to_excel(writer, sheet_name=f"bm_w_filtered_grouped{code}", index=True)
                #     bm_r_filtered_grouped.to_excel(writer, sheet_name=f"bm_r_filtered_grouped{code}", index=True)
                #     bm_ctr_filtered.to_excel(writer, sheet_name=f"bm_ctr_filtered{code}", index=True)
                #     ap_w_filtered_grouped.to_excel(writer, sheet_name=f"ap_w_filtered_grouped{code}", index=True)
                #     ë‹¨ê°€_r_filtered_grouped.to_excel(writer, sheet_name=f"ë‹¨ê°€_r_filtered_grouped{code}", index=True)
                #     ctr_df_grouped.to_excel(writer, sheet_name=f"ctr_df_grouped{code}", index=True)
                #     ê°€ì¤‘í‰ê· ìˆ˜ìµë¥ .to_excel(writer, sheet_name=f"ê°€ì¤‘í‰ê· ìˆ˜ìµë¥ {code}", index=True)

            except Exception as e:
                print(f"Error calculating ìˆ˜ìµì°¨ for {code}: {e}")

        return ìˆ˜ìµì°¨

    # í•¨ìˆ˜ í˜¸ì¶œ
    ìˆ˜ìµì°¨ = generate_ìˆ˜ìµì°¨(PV_ctr, AP_W, dict_FUND_CD, BMW_30, BMW_50, BMW_70, BMW_í‡´ì§70, BM_R, ë‹¨ê°€_R, dict_BM)



    def generate_Total_BM(BMW_dict, BM_R):
        Total_BM = {}
        BM_ctr = {}

        for code, bmw_df in BMW_dict.items():
            if not isinstance(bmw_df, pd.DataFrame):
                print(f"{code}ì˜ ë°ì´í„°ê°€ DataFrame í˜•ì‹ì´ ì•„ë‹™ë‹ˆë‹¤. ì „ë‹¬ëœ ë°ì´í„°: {type(bmw_df)}")
                continue

            # ì¸ë±ìŠ¤ë¥¼ datetime í˜•ì‹ìœ¼ë¡œ ë³€í™˜
            bmw_df.index = pd.to_datetime(bmw_df.index, errors="coerce")
            BM_R.index = pd.to_datetime(BM_R.index, errors="coerce")

            # ê³µí†µ ì—´ í™•ì¸
            common_columns = list(set(bmw_df.columns.astype(str)) & set(BM_R.columns.astype(str)))

            if not common_columns:
                print(f"ê³µí†µ ì—´ì´ ì—†ìŠµë‹ˆë‹¤: {code}")
                continue

            # ê³µí†µ ì—´ë¡œ ë°ì´í„° í•„í„°ë§
            filtered_bmw = bmw_df[common_columns]
            filtered_bm_r = BM_R[common_columns]

            # BMWì™€ BM_R ê³±í•˜ì—¬ BM_ctr ê³„ì‚°
            bm_ctr_df = filtered_bmw * (filtered_bm_r)
            BM_ctr[code] = bm_ctr_df

            # ì´ BM ê³„ì‚°
            sum_BM_ctr = bm_ctr_df.sum(axis=1)

            # ëˆ„ì  ìˆ˜ìµë¥  ê³„ì‚°
            Total_BM_cum = (1 + sum_BM_ctr).cumprod() - 1

            # ê²°ê³¼ ì €ì¥
            Total_BM[code] = Total_BM_cum

            # ì—‘ì…€ ì €ì¥
            # with pd.ExcelWriter(path, engine="openpyxl", mode="a", if_sheet_exists="replace") as writer:
            #     # BM_ctr ì €ì¥
            #     BM_ctr_df = BM_ctr[code]  # dictì—ì„œ codeì— í•´ë‹¹í•˜ëŠ” ê°’ì„ ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ ê°€ì ¸ì˜´
            #     BM_ctr_df.to_excel(writer, sheet_name=f"BM_ctr_{code}_{sheet}", index=True)

            #     # Total_BM ì €ì¥
            #     Total_BM_cum = Total_BM[code].to_frame(name=f"Total_BM_{code}_{sheet}")
            #     Total_BM_cum.to_excel(writer, sheet_name=f"Total_BM_{code}_{sheet}", index=True)

            #     # print(f"Total_BM_{code}_{sheet} ë° BM_ctr_{code}_{sheet} ì €ì¥ ì™„ë£Œ.")

        return Total_BM, BM_ctr



    # Example function call
    Total_BM, BM_ctr = generate_Total_BM(
        {"30": BMW_30, "50": BMW_50, "70": BMW_70, "í‡´ì§70": BMW_í‡´ì§70},
        BM_R
    )



    def generate_ì´ˆê³¼ìˆ˜ìµ(
        PV_ctr, BM_ctr, dict_FUND_CD, 
        BMW_30, ctBMW_50, BMW_70, BMW_í‡´ì§70, 
        BM_R, dict_BM, PV_ë¶„ë°°ê¸ˆë¹„ìœ¨
    ):
        
        EX_R = {}

        for code, pv_data in PV_ctr.items():
            print(f"Processing ì´ˆê³¼ìˆ˜ìµ for {code}")

            # BMW ì„ íƒ
            fund_name = dict_FUND_CD.get(code, "")
            bmw_df = (
                BMW_30 if "30" in fund_name else
                BMW_50 if "50" in fund_name else
                BMW_70 if "70" in fund_name and "í‡´ì§" not in fund_name else
                BMW_í‡´ì§70 if "í‡´ì§70" in fund_name else None
            )

            if bmw_df is None:
                print(f"{code}ì— ëŒ€í•œ BMW ë§¤ì¹­ ì¡°ê±´ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                continue

            # ê³µí†µ ì—´ ì •ì˜
            common_columns = list(set(bmw_df.columns.astype(str)) & set(BM_R.columns.astype(str)))
            if not common_columns:
                print(f"{code}ì— ê³µí†µ ì—´ì´ ì—†ìŠµë‹ˆë‹¤.")
                continue

            # BM_ctr ê³„ì‚°
            BM_ctr[code] = bmw_df[common_columns] * BM_R[common_columns]

            # ì—´ ì´ë¦„ ë§¤í•‘



            pv_data = rename_col_to_dict_value(pv_data, dict_BM)

            # ê·¸ë£¹í™” ë° ê³µí†µ ì—´ ê³„ì‚°
            grouped_PV_ctr = pv_data.groupby(pv_data.columns, axis=1).sum()
            common_columns = list(set(grouped_PV_ctr.columns.astype(str)) & set(BM_ctr[code].columns.astype(str)))
            if not common_columns:
                print(f"ì´ˆê³¼ ìˆ˜ìµ ê³„ì‚° ê³µí†µ ì—´ì´ ì—†ìŠµë‹ˆë‹¤: {code}")
                continue

            grouped_PV_ctr = grouped_PV_ctr[common_columns].reindex(grouped_PV_ctr.index).fillna(0)
            
            # ë¶„ë°°ê¸ˆ ì—´ ì¶”ê°€
            if 'ë¶„ë°°ê¸ˆ' not in grouped_PV_ctr.columns:
                grouped_PV_ctr['ë¶„ë°°ê¸ˆ'] = PV_ë¶„ë°°ê¸ˆë¹„ìœ¨.get(code, pd.Series(index=grouped_PV_ctr.index, dtype=float))
            
            
            BM_ctr_filtered = BM_ctr[code].reindex(grouped_PV_ctr.index).fillna(0)
            BM_ctr_filtered['ë¶„ë°°ê¸ˆ'] = 0


            # print("grouped_PV_ctr********************", grouped_PV_ctr)
            # print("BM_ctr_filtered********************", BM_ctr_filtered)

            # ì´ˆê³¼ ìˆ˜ìµë¥  ê³„ì‚°
            try:
                ex_r_df = grouped_PV_ctr - BM_ctr_filtered
                EX_R[code] = ex_r_df
                cum_EX_R = (1 + ex_r_df).cumprod() - 1



            except Exception as e:
                print(f"Error calculating EX_R for {code}: {e}")
                continue



        # # Save the results to Excel
        # with pd.ExcelWriter(path, engine='openpyxl', mode='a', if_sheet_exists='replace') as writer:
        #     for code, ex_r_df in EX_R.items():
        #         ex_r_df.to_excel(writer, sheet_name=f"EX_R_{code}_{sheet}", index=True)
        #         cum_EX_R.to_excel(writer, sheet_name=f"cum_EX_R{code}_{sheet}", index=True)

        #         print(f"'{code}' ì´ˆê³¼ ìˆ˜ìµ ì €ì¥ ì™„ë£Œ.")
            
                    
        #         grouped_PV_ctr.to_excel(writer, sheet_name=f"grouped_PV_ctr_{code}_{sheet}", index=True)
        #         print(f"'{code}' grouped_PV_ctr ì €ì¥ ì™„ë£Œ.")

        return EX_R, BM_ctr_filtered, grouped_PV_ctr



    EX_R, BM_ctr_filtered, grouped_PV_ctr = generate_ì´ˆê³¼ìˆ˜ìµ(
        PV_ctr, BM_ctr, dict_FUND_CD, 
        BMW_30, BMW_50, BMW_70, BMW_í‡´ì§70, 
        BM_R, dict_BM, PV_ë¶„ë°°ê¸ˆë¹„ìœ¨
    )



    def merge_ì¢…í•©(EX_R, ìì‚°ì°¨, ìˆ˜ìµì°¨, AP_W, dict_FUND_CD, BMW_30, BMW_50, BMW_70, BMW_í‡´ì§70):
        # ìµœì¢… ê²°ê³¼ ì €ì¥ìš© ë°ì´í„°í”„ë ˆì„ ë¦¬ìŠ¤íŠ¸
        results = []

        for code in ìì‚°ì°¨.keys():
            # ìì‚°ì°¨ ë§ˆì§€ë§‰ í–‰ ì¶”ì¶œ
            ìì‚°ì°¨_last_row = ìì‚°ì°¨[code].iloc[-1]
            ìì‚°ì°¨_last_row.name = f"{code}_ìì‚°ì°¨"

            # ìˆ˜ìµì°¨ ë§ˆì§€ë§‰ í–‰ ì¶”ì¶œ
            if code in ìˆ˜ìµì°¨:
                ìˆ˜ìµì°¨_last_row = ìˆ˜ìµì°¨[code].iloc[-1]
                ìˆ˜ìµì°¨_last_row.name = f"{code}_ìˆ˜ìµì°¨"
            else:
                ìˆ˜ìµì°¨_last_row = pd.Series(0, index=ìì‚°ì°¨_last_row.index, name=f"{code}_ìˆ˜ìµì°¨")

            # EX_R ë§ˆì§€ë§‰ í–‰ ì¶”ì¶œ
            if code in EX_R:
                ex_r_last_row = ((1+EX_R[code]).cumprod()-1).iloc[-1]
                ex_r_last_row.name = f"{code}_ì´ˆê³¼ìˆ˜ìµ"
            else:
                ex_r_last_row = pd.Series(0, index=ìì‚°ì°¨_last_row.index, name=f"{code}_ì´ˆê³¼ìˆ˜ìµ")

            # AP_W ë§ˆì§€ë§‰ í–‰ ì¶”ì¶œ
            if code in AP_W:
                ap_w_last_row = AP_W[code].mean()
                ap_w_last_row.name = f"{code}_AP_W"
            else:
                ap_w_last_row = pd.Series(0, index=ìì‚°ì°¨_last_row.index, name=f"{code}_AP_W")

            # BMW ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
            fund_name = dict_FUND_CD.get(code, "")
            if "30" in fund_name:
                bmw_df = BMW_30
            elif "50" in fund_name:
                bmw_df = BMW_50
            elif "70" in fund_name and "í‡´ì§" not in fund_name:
                bmw_df = BMW_70
            elif "í‡´ì§70" in fund_name:
                bmw_df = BMW_í‡´ì§70
            else:
                bmw_df = None

            # BMW ë§ˆì§€ë§‰ í–‰ ì¶”ì¶œ
            if bmw_df is not None:
                bm_w_last_row = bmw_df.mean()
                bm_w_last_row.name = f"{code}_BMW"
            else:
                bm_w_last_row = pd.Series(0, index=ìì‚°ì°¨_last_row.index, name=f"{code}_BMW")

            # ê¸°íƒ€ì°¨ ê³„ì‚° (ì´ˆê³¼ìˆ˜ìµ - (ìì‚°ì°¨ + ìˆ˜ìµì°¨))
            ê¸°íƒ€ì°¨_last_row = ex_r_last_row - (ìì‚°ì°¨_last_row + ìˆ˜ìµì°¨_last_row)
            ê¸°íƒ€ì°¨_last_row.name = f"{code}_ê¸°íƒ€ì°¨"

            # ë³‘í•©í•  ì‹œë¦¬ì¦ˆë¥¼ ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€
            results.append(ap_w_last_row)
            results.append(bm_w_last_row)
            results.append(ex_r_last_row)
            results.append(ìì‚°ì°¨_last_row)
            results.append(ìˆ˜ìµì°¨_last_row)
            results.append(ê¸°íƒ€ì°¨_last_row)

        # ì¤‘ë³µëœ ì¸ë±ìŠ¤ í™•ì¸ ë° ì œê±°
        for i, series in enumerate(results):
            if series.index.duplicated().any():
                series = series[~series.index.duplicated(keep="first")]
                results[i] = series

        # ë³‘í•©ëœ ê²°ê³¼ë¥¼ ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ ë³€í™˜
        try:
            ì¢…í•© = pd.concat(results, axis=1).T.fillna(0)
        except ValueError as e:
            print(f"ë³‘í•© ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            # ì¸ë±ìŠ¤ë¥¼ ê³ ìœ í•˜ê²Œ ë³€ê²½
            unique_results = [series.reset_index(drop=True) for series in results]
            ì¢…í•© = pd.concat(unique_results, axis=1).T.fillna(0)

        # í•©ê³„ ì—´ ì¶”ê°€
        ì¢…í•©["í•©ê³„"] = ì¢…í•©.sum(axis=1)

        # ì—‘ì…€ ì €ì¥
        with pd.ExcelWriter(path, engine='openpyxl', mode='a', if_sheet_exists='replace') as writer:
            ì¢…í•©.to_excel(writer, sheet_name=f"ì¢…í•©_{sheet}", index=True)
            print(f"{path}ì— ì¢…í•© ì €ì¥ ì™„ë£Œ.")

        # ê²°ê³¼ ë°˜í™˜
        return ì¢…í•©

    # í•¨ìˆ˜ í˜¸ì¶œ
    ì¢…í•© = merge_ì¢…í•©(EX_R, ìì‚°ì°¨, ìˆ˜ìµì°¨, AP_W, dict_FUND_CD, BMW_30, BMW_50, BMW_70, BMW_í‡´ì§70)


    # ê²°ê³¼ ì¶œë ¥
    print("ìì‚°ì°¨, ìˆ˜ìµì°¨, ì´ˆê³¼ìˆ˜ìµ ë³‘í•© ê²°ê³¼ ====================================", ì¢…í•©)
    

    print("*********************ì‘ì—…ì™„ë£Œ*******************")
